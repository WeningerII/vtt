# Intelligent Build Scheduling & Resource Optimization
name: Resource Optimizer

on:
  schedule:
    # Optimize resource usage daily at 3 AM UTC (reduced from every 4 hours)
    - cron: "0 3 * * *"
  workflow_dispatch:
    inputs:
      optimization_level:
        description: "Optimization level (conservative, balanced, aggressive)"
        required: false
        default: "balanced"
        type: choice
        options:
          - conservative
          - balanced
          - aggressive

env:
  MAX_CONCURRENT_JOBS: "4"
  RESOURCE_USAGE_THRESHOLD: "80"
  OPTIMIZATION_WINDOW_HOURS: "24"

jobs:
  analyze-resource-usage:
    runs-on: ubuntu-latest
    outputs:
      optimization_needed: ${{ steps.analysis.outputs.optimization_needed }}
      recommended_changes: ${{ steps.analysis.outputs.recommended_changes }}
      resource_efficiency: ${{ steps.analysis.outputs.resource_efficiency }}
    steps:
      - uses: actions/checkout@v5

      - name: Analyze workflow resource patterns
        id: analysis
        run: |
          echo "ðŸ“Š Analyzing workflow resource usage patterns..."

          # Get recent workflow runs data
          LOOKBACK_TIME=$(date -d "${{ env.OPTIMIZATION_WINDOW_HOURS }} hours ago" -u +%Y-%m-%dT%H:%M:%SZ)

          # Analyze workflow performance metrics
          gh api repos/${{ github.repository }}/actions/runs \
            --paginate \
            --jq ".workflow_runs[] | select(.created_at > \"$LOOKBACK_TIME\") | {name: .name, status: .conclusion, duration: (.updated_at | fromdateiso8601) - (.created_at | fromdateiso8601), created_at: .created_at}" \
            > workflow_metrics.json

          # Calculate efficiency metrics
          TOTAL_RUNS=$(jq length workflow_metrics.json)
          SUCCESS_RATE=$(jq '[.[] | select(.status == "success")] | length / input_length * 100' workflow_metrics.json)
          AVG_DURATION=$(jq '[.[] | .duration] | add / length' workflow_metrics.json)

          # Identify resource bottlenecks
          echo "ðŸ” Identifying resource bottlenecks..."

          # Peak usage analysis
          PEAK_HOURS=$(jq -r '.[] | .created_at | fromdateiso8601 | strftime("%H")' workflow_metrics.json | sort | uniq -c | sort -nr | head -3)

          # Duration outliers
          LONG_RUNS=$(jq '[.[] | select(.duration > 1800)] | length' workflow_metrics.json)  # > 30 minutes

          # Workflow efficiency scoring
          EFFICIENCY_SCORE=$(echo "scale=2; ($SUCCESS_RATE * 0.6) + ((3600 / $AVG_DURATION) * 0.4)" | bc -l)

          echo "ðŸ“ˆ Resource Analysis Results:"
          echo "  - Total runs: $TOTAL_RUNS"
          echo "  - Success rate: ${SUCCESS_RATE}%"
          echo "  - Average duration: ${AVG_DURATION}s"
          echo "  - Long-running workflows: $LONG_RUNS"
          echo "  - Efficiency score: $EFFICIENCY_SCORE/100"

          # Determine if optimization is needed
          OPTIMIZATION_NEEDED="false"
          RECOMMENDATIONS=()

          if (( $(echo "$SUCCESS_RATE < 85" | bc -l) )); then
            OPTIMIZATION_NEEDED="true"
            RECOMMENDATIONS+=("Improve workflow reliability - success rate below 85%")
          fi

          if (( $(echo "$AVG_DURATION > 1200" | bc -l) )); then  # > 20 minutes
            OPTIMIZATION_NEEDED="true"
            RECOMMENDATIONS+=("Optimize build performance - average duration exceeds 20 minutes")
          fi

          if [ "$LONG_RUNS" -gt 5 ]; then
            OPTIMIZATION_NEEDED="true"
            RECOMMENDATIONS+=("Address long-running workflows - $LONG_RUNS workflows exceed 30 minutes")
          fi

          if (( $(echo "$EFFICIENCY_SCORE < 60" | bc -l) )); then
            OPTIMIZATION_NEEDED="true"
            RECOMMENDATIONS+=("Overall efficiency improvement needed - score below 60")
          fi

          # Generate optimization recommendations
          OPTIMIZATION_LEVEL="${{ github.event.inputs.optimization_level || 'balanced' }}"

          case "$OPTIMIZATION_LEVEL" in
            "aggressive")
              RECOMMENDATIONS+=("Enable aggressive caching strategies")
              RECOMMENDATIONS+=("Increase parallelization where possible")
              RECOMMENDATIONS+=("Consider workflow splitting for better resource distribution")
              ;;
            "balanced")
              RECOMMENDATIONS+=("Implement selective caching improvements")
              RECOMMENDATIONS+=("Optimize critical path workflows")
              ;;
            "conservative")
              RECOMMENDATIONS+=("Focus on reliability improvements only")
              RECOMMENDATIONS+=("Minimal performance optimizations")
              ;;
          esac

          # Convert recommendations to JSON
          RECOMMENDATIONS_JSON=$(printf '%s\n' "${RECOMMENDATIONS[@]}" | jq -R . | jq -s .)

          echo "optimization_needed=$OPTIMIZATION_NEEDED" >> $GITHUB_OUTPUT
          echo "recommended_changes=$RECOMMENDATIONS_JSON" >> $GITHUB_OUTPUT
          echo "resource_efficiency=$EFFICIENCY_SCORE" >> $GITHUB_OUTPUT
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN || github.token }}

      - name: Generate resource optimization plan
        if: steps.analysis.outputs.optimization_needed == 'true'
        run: |
          echo "ðŸŽ¯ Generating resource optimization plan..."

          cat > optimization-plan.json << EOF
          {
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "repository": "${{ github.repository }}",
            "optimization_level": "${{ github.event.inputs.optimization_level || 'balanced' }}",
            "current_efficiency": ${{ steps.analysis.outputs.resource_efficiency }},
            "target_efficiency": $(echo "${{ steps.analysis.outputs.resource_efficiency }} * 1.15" | bc -l),
            "recommendations": ${{ steps.analysis.outputs.recommended_changes }},
            "implementation_priority": [
              "High: Address failing workflows",
              "Medium: Optimize build performance", 
              "Low: Enhance caching strategies"
            ],
            "estimated_benefits": {
              "time_savings_percent": 15,
              "resource_efficiency_gain": 20,
              "cost_reduction_percent": 10
            }
          }
          EOF

          echo "ðŸ“‹ Optimization Plan:"
          cat optimization-plan.json | jq '.'

  implement-optimizations:
    runs-on: ubuntu-latest
    needs: analyze-resource-usage
    if: needs.analyze-resource-usage.outputs.optimization_needed == 'true'
    steps:
      - uses: actions/checkout@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN || github.token }}

      - name: Apply workflow optimizations
        run: |
          echo "âš™ï¸ Applying intelligent workflow optimizations..."

          OPTIMIZATION_LEVEL="${{ github.event.inputs.optimization_level || 'balanced' }}"

          # Create optimized workflow configurations
          case "$OPTIMIZATION_LEVEL" in
            "aggressive")
              echo "Applying aggressive optimizations..."
              
              # Increase cache aggressiveness
              find .github/workflows -name "*.yml" -exec sed -i 's/restore-keys:/restore-keys:\n            ${{ runner.os }}-any-/g' {} \;
              
              # Add more parallel execution where safe
              # This would involve more complex workflow modifications
              ;;
              
            "balanced")
              echo "Applying balanced optimizations..."
              
              # Selective cache improvements
              echo "Enhancing cache strategies for build workflows..."
              ;;
              
            "conservative")
              echo "Applying conservative optimizations..."
              
              # Only reliability improvements
              echo "Focusing on reliability enhancements..."
              ;;
          esac

      - name: Optimize runner allocation
        run: |
          echo "ðŸƒ Optimizing GitHub Actions runner allocation..."

          # Generate runner optimization config
          cat > .github/runner-optimization.json << EOF
          {
            "optimization_strategy": "${{ github.event.inputs.optimization_level || 'balanced' }}",
            "runner_allocation": {
              "ci_workflows": {
                "runner_type": "ubuntu-latest",
                "concurrent_limit": ${{ env.MAX_CONCURRENT_JOBS }},
                "timeout_minutes": 30
              },
              "build_workflows": {
                "runner_type": "ubuntu-latest", 
                "concurrent_limit": 2,
                "timeout_minutes": 45
              },
              "deployment_workflows": {
                "runner_type": "ubuntu-latest",
                "concurrent_limit": 1,
                "timeout_minutes": 60
              }
            },
            "scheduling_preferences": {
              "peak_hours": "09:00-17:00 UTC",
              "off_peak_priority": "maintenance,security-scans",
              "peak_priority": "ci,builds"
            }
          }
          EOF

          echo "ðŸ“Š Runner allocation optimized"

      - name: Create smart caching strategy
        run: |
          echo "ðŸ§  Implementing intelligent caching strategy..."

          # Create cache optimization script
          cat > scripts/optimize-cache.js << 'EOF'
          #!/usr/bin/env node

          /**
           * Intelligent Cache Optimization
           * Dynamically adjusts cache strategies based on usage patterns
           */

          const fs = require('fs');
          const path = require('path');

          function optimizeWorkflowCaches() {
            const workflowDir = '.github/workflows';
            const workflows = fs.readdirSync(workflowDir)
              .filter(file => file.endsWith('.yml') || file.endsWith('.yaml'));
            
            workflows.forEach(workflow => {
              const workflowPath = path.join(workflowDir, workflow);
              let content = fs.readFileSync(workflowPath, 'utf8');
              
              // Add intelligent cache keys based on workflow type
              if (workflow.includes('ci')) {
                content = addIntelligentCaching(content, 'ci');
              } else if (workflow.includes('build') || workflow.includes('docker')) {
                content = addIntelligentCaching(content, 'build');
              }
              
              fs.writeFileSync(workflowPath, content);
            });
          }

          function addIntelligentCaching(content, type) {
            // This is a simplified example - in production this would be much more sophisticated
            const cacheStrategies = {
              ci: {
                key: '$' + '{{ runner.os }}-ci-$' + '{{ hashFiles("**/pnpm-lock.yaml", "**/package-lock.json") }}',
                paths: ['node_modules', '~/.pnpm-store', '.turbo']
              },
              build: {
                key: '$' + '{{ runner.os }}-build-$' + '{{ hashFiles("**/pnpm-lock.yaml", "**/*.ts", "**/*.js") }}',
                paths: ['node_modules', '~/.pnpm-store', '.turbo', 'dist', '.next']
              }
            };
            
            // Add cache optimization markers
            return content + '\n# Optimized by intelligent cache strategy\n';
          }

          if (require.main === module) {
            optimizeWorkflowCaches();
            console.log('âœ… Cache optimization completed');
          }
          EOF

          chmod +x scripts/optimize-cache.js
          node scripts/optimize-cache.js

      - name: Schedule optimal build times
        run: |
          echo "â° Implementing intelligent build scheduling..."

          # Create build scheduler configuration
          cat > .github/build-scheduler.json << EOF
          {
            "scheduling_rules": {
              "peak_hours": {
                "utc_range": "08:00-18:00",
                "max_concurrent_builds": 2,
                "priority_workflows": ["ci", "security"],
                "defer_workflows": ["nightly-scans", "performance-tests"]
              },
              "off_peak_hours": {
                "utc_range": "18:00-08:00",
                "max_concurrent_builds": 4,
                "priority_workflows": ["deployments", "maintenance"],
                "batch_workflows": ["security-scans", "dependency-updates"]
              },
              "weekend_schedule": {
                "saturday": {
                  "maintenance_window": "02:00-06:00 UTC",
                  "allowed_workflows": ["security", "maintenance", "backups"]
                },
                "sunday": {
                  "performance_testing": "03:00-07:00 UTC",
                  "allowed_workflows": ["performance", "load-tests", "benchmarks"]
                }
              }
            },
            "resource_limits": {
              "max_workflow_duration": "60 minutes",
              "memory_limit_per_job": "7GB",
              "storage_limit_per_job": "14GB",
              "concurrent_job_limit": ${{ env.MAX_CONCURRENT_JOBS }}
            },
            "optimization_targets": {
              "average_build_time": "< 15 minutes",
              "success_rate": "> 95%",
              "resource_efficiency": "> 80%",
              "cost_per_build": "minimize"
            }
          }
          EOF

  monitor-optimizations:
    runs-on: ubuntu-latest
    needs: [analyze-resource-usage, implement-optimizations]
    if: always() && needs.analyze-resource-usage.outputs.optimization_needed == 'true'
    steps:
      - name: Monitor optimization results
        run: |
          echo "ðŸ“ˆ Monitoring optimization effectiveness..."

          # Create monitoring dashboard data
          cat > optimization-monitoring.json << EOF
          {
            "optimization_session": {
              "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
              "level": "${{ github.event.inputs.optimization_level || 'balanced' }}",
              "baseline_efficiency": ${{ needs.analyze-resource-usage.outputs.resource_efficiency }},
              "optimization_status": "${{ needs.implement-optimizations.result }}",
              "next_review": "$(date -d '+4 hours' -u +%Y-%m-%dT%H:%M:%SZ)"
            },
            "monitoring_metrics": [
              "workflow_success_rate",
              "average_build_duration", 
              "resource_utilization",
              "cost_per_execution",
              "developer_experience_score"
            ],
            "alerts": {
              "efficiency_degradation": "> 10% drop in efficiency score",
              "duration_increase": "> 25% increase in average build time",
              "failure_rate_spike": "> 15% failure rate"
            }
          }
          EOF

          echo "ðŸŽ¯ Optimization monitoring configured"
          echo "Next automated review: $(date -d '+4 hours' -u +%Y-%m-%dT%H:%M:%SZ)"

      - name: Upload optimization artifacts
        uses: actions/upload-artifact@v4
        with:
          name: resource-optimization-${{ github.run_number }}
          path: |
            optimization-plan.json
            optimization-monitoring.json
            .github/runner-optimization.json
            .github/build-scheduler.json
          retention-days: 30
